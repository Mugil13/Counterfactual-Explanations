{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This file contains the procedure for creating Counterfactual Maps and visualizing them with the help of the MNIST Dataset"
      ],
      "metadata": {
        "id": "9fmS2zw-g0Hc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "Gy92SdOeVekx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p24uGS_spVAt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a basic classifier"
      ],
      "metadata": {
        "id": "zDM6bBOPVhTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]\n",
        "\n",
        "class MNISTClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 10, kernel_size=5),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(10, 20, kernel_size=5),\n",
        "            nn.Dropout(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(320, 50),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(50, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "o4OjdQ6xqi49"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-requisites"
      ],
      "metadata": {
        "id": "pRxtK9D-VnbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Union, List\n",
        "import numpy as np\n",
        "from PIL import Image as PilImage\n",
        "\n",
        "class Image(Data):\n",
        "    data_type = \"image\"\n",
        "\n",
        "    def __init__(self, data: Union[np.ndarray, PilImage.Image] = None, batched: bool = False, channel_last: bool = True):\n",
        "        super().__init__()\n",
        "        if data is None:\n",
        "            self.data = None\n",
        "        elif isinstance(data, np.ndarray):\n",
        "            self.data = self._check_and_unify(data, batched, channel_last)\n",
        "        elif isinstance(data, PilImage.Image):\n",
        "            self.data = self._check_and_unify(np.array(data), batched=False, channel_last=True)\n",
        "        else:\n",
        "            raise ValueError(f\"`data` must be `np.ndarray` or `PIL.Image`, not {type(data)}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _check_and_unify(data: np.ndarray, batched: bool, channel_last: bool):\n",
        "        if batched:\n",
        "            assert data.ndim in [3, 4], (\n",
        "                f\"`batched = True`, but got shape {data.shape}\"\n",
        "            )\n",
        "            img = data[0]\n",
        "        else:\n",
        "            assert data.ndim in [2, 3], (\n",
        "                f\"`batched = False`, but got shape {data.shape}\"\n",
        "            )\n",
        "            img = data\n",
        "\n",
        "        if img.ndim == 3:\n",
        "            if channel_last:\n",
        "                assert img.shape[2] <= 4, \"Last dimension should be color channels.\"\n",
        "            else:\n",
        "                assert img.shape[0] <= 4, \"First dimension should be color channels.\"\n",
        "\n",
        "        if not batched:\n",
        "            data = np.expand_dims(data, axis=0)\n",
        "        if data.ndim == 4 and not channel_last:\n",
        "            data = np.transpose(data, (0, 2, 3, 1))\n",
        "        elif data.ndim == 3:\n",
        "            data = np.expand_dims(data, axis=-1)\n",
        "        return data\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, i: Union[int, slice, list]):\n",
        "        if isinstance(i, int):\n",
        "            return Image(self.data[i:i+1], batched=True, channel_last=True)\n",
        "        return Image(self.data[i], batched=True, channel_last=True)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return (self[i] for i in range(self.shape[0]))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return repr(self.data)\n",
        "\n",
        "    @property\n",
        "    def shape(self) -> tuple:\n",
        "        return self.data.shape\n",
        "\n",
        "    @property\n",
        "    def image_shape(self) -> tuple:\n",
        "        return self.data.shape[1:]\n",
        "\n",
        "    @property\n",
        "    def values(self) -> np.ndarray:\n",
        "        return self.data\n",
        "\n",
        "    def num_samples(self) -> int:\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def to_numpy(self, hwc=True, copy=True, keepdim=False) -> np.ndarray:\n",
        "        data = self.data.copy() if copy else self.data\n",
        "        if not keepdim and self.shape[-1] == 1:\n",
        "            return data.squeeze(axis=-1)\n",
        "        return data if hwc else np.transpose(data, (0, 3, 1, 2))\n",
        "\n",
        "    def to_pil(self) -> Union[PilImage.Image, List[PilImage.Image]]:\n",
        "        x = self.data.squeeze(axis=-1) if self.shape[-1] == 1 else self.data\n",
        "        if self.shape[0] == 1:\n",
        "            return PilImage.fromarray(x[0].astype(np.uint8))\n",
        "        return [PilImage.fromarray(x[i].astype(np.uint8)) for i in range(self.shape[0])]\n",
        "\n",
        "    def copy(self):\n",
        "        return Image(data=self.data.copy(), batched=True, channel_last=True)"
      ],
      "metadata": {
        "id": "KUgC9WW_rBZd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the dataset"
      ],
      "metadata": {
        "id": "2-3pen3XdMp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST training and test datasets\n",
        "train_data = torchvision.datasets.MNIST(root='../data', train=True, download=True)\n",
        "test_data = torchvision.datasets.MNIST(root='../data', train=False, download=True)\n",
        "\n",
        "# Convert image data to NumPy arrays\n",
        "train_data.data = train_data.data.numpy()\n",
        "test_data.data = test_data.data.numpy()\n",
        "\n",
        "# Define class labels\n",
        "class_names = tuple(range(10))\n",
        "\n",
        "# Wrap datasets with the custom Image class\n",
        "x_train, y_train = Image(train_data.data, batched=True), train_data.targets\n",
        "x_test, y_test = Image(test_data.data, batched=True), test_data.targets"
      ],
      "metadata": {
        "id": "mkTFpQ4sq2zO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "debb342d-66a9-4155-cf47-6222713b345c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 52.2MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 2.19MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.2MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.31MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up your device"
      ],
      "metadata": {
        "id": "5ID1siIrdY9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Initialize the CNN model\n",
        "model = MNISTClassifier().to(device)\n",
        "\n",
        "# Define preprocessing function\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "preprocess = lambda ims: torch.stack([transform(im.to_pil()) for im in ims])"
      ],
      "metadata": {
        "id": "LMb-WlqNq-Z0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation"
      ],
      "metadata": {
        "id": "f2rR1DU-eusz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "learning_rate = 1e-3\n",
        "batch_size = 128\n",
        "num_epochs = 10\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(\n",
        "    dataset=MNISTDataset(preprocess(x_train), y_train),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    dataset=MNISTDataset(preprocess(x_test), y_test),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        loss = loss_func(model(x), y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluation\n",
        "correct_pred = {name: 0 for name in class_names}\n",
        "total_pred = {name: 0 for name in class_names}\n",
        "\n",
        "model.eval()\n",
        "for x, y in test_loader:\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    outputs = model(x)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    for label, pred in zip(y, preds):\n",
        "        if label == pred:\n",
        "            correct_pred[class_names[label]] += 1\n",
        "        total_pred[class_names[label]] += 1\n",
        "\n",
        "# Print class-wise accuracy\n",
        "for name, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[name]\n",
        "    print(f\"Accuracy for class {name} is: {accuracy:.1f} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLd8SyImsWlE",
        "outputId": "7d1b3f36-aa3e-4150-a030-308746187ec3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class 0 is: 99.5 %\n",
            "Accuracy for class 1 is: 99.7 %\n",
            "Accuracy for class 2 is: 99.2 %\n",
            "Accuracy for class 3 is: 98.7 %\n",
            "Accuracy for class 4 is: 98.6 %\n",
            "Accuracy for class 5 is: 99.1 %\n",
            "Accuracy for class 6 is: 99.2 %\n",
            "Accuracy for class 7 is: 97.5 %\n",
            "Accuracy for class 8 is: 99.1 %\n",
            "Accuracy for class 9 is: 97.4 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Explainer Module"
      ],
      "metadata": {
        "id": "F5VYsDaBe2XC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import inspect\n",
        "\n",
        "_EXPLAINERS = defaultdict(list)\n",
        "\n",
        "#Metaclass for registering explainer classes into `_EXPLAINERS`\n",
        "class ExplainerABCMeta(AutodocABCMeta):\n",
        "    def __new__(mcls, classname, bases, cls_dict):\n",
        "        cls = super().__new__(mcls, classname, bases, cls_dict)\n",
        "        if not inspect.isabstract(cls):\n",
        "            module_name = cls.__module__.split(\".\")[2]\n",
        "            class_name = cls.__name__\n",
        "            if class_name in _EXPLAINERS[module_name]:\n",
        "                raise RuntimeError(\n",
        "                    f\"Explainer class `{class_name}` already exists in `{module_name}`. Please use a unique name.\"\n",
        "                )\n",
        "            _EXPLAINERS[module_name].append(cls)\n",
        "        return cls"
      ],
      "metadata": {
        "id": "_Iy7mpx_uXfs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "import os\n",
        "import dill\n",
        "from copy import deepcopy\n",
        "from abc import abstractmethod\n",
        "\n",
        "class ExplainerBase(metaclass=AutodocABCMeta):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def explain(self, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @property\n",
        "    def explanation_type(self):\n",
        "        return \"local\"\n",
        "\n",
        "    def __getstate__(self):\n",
        "        return {k: deepcopy(v) for k, v in self.__dict__.items()}\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        for name, value in state.items():\n",
        "            setattr(self, name, value)\n",
        "\n",
        "    def save(self, directory: str, filename: str = None, **kwargs):\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "        if filename is None:\n",
        "            filename = f\"{type(self).__name__}.pkl\"\n",
        "        state = self.__getstate__()\n",
        "        for attr in kwargs.get(\"ignored_attributes\", []):\n",
        "            state.pop(attr, None)\n",
        "        with open(os.path.join(directory, filename), \"wb\") as f:\n",
        "            dill.dump(state, f)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, directory: str, filename: str = None, **kwargs):\n",
        "        if filename is None:\n",
        "            filename = f\"{cls.__name__}.pkl\"\n",
        "        with open(os.path.join(directory, filename), \"rb\") as f:\n",
        "            state = dill.load(f)\n",
        "        instance = super(ExplainerBase, cls).__new__(cls)\n",
        "        instance.__setstate__(state)\n",
        "        return instance"
      ],
      "metadata": {
        "id": "P9o-2M4WuD08"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Abstract base class for explanation results\n",
        "class ExplanationBase(metaclass=AutodocABCMeta):\n",
        "    @abstractmethod\n",
        "    def get_explanations(self, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def plot(self, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def plotly_plot(self, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def ipython_plot(self, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def dump(self, file):\n",
        "        dill.dump(self, file)\n",
        "\n",
        "    def load(self, file):\n",
        "        return dill.load(file)\n",
        "\n",
        "    def dumps(self):\n",
        "        return dill.dumps(self)\n",
        "\n",
        "    def loads(self, byte_string):\n",
        "        return dill.loads(byte_string)\n",
        "\n",
        "    @staticmethod\n",
        "    def _s(s, max_len=15):\n",
        "        if isinstance(s, str):\n",
        "            return s[:max_len] + \"*\" if len(s) > max_len else s\n",
        "        elif isinstance(s, float):\n",
        "            return int(s) if s.is_integer() else \"{:.3f}\".format(s)\n",
        "        return s\n",
        "\n",
        "    def to_json(self):\n",
        "        import json\n",
        "        from .utils import DefaultJsonEncoder\n",
        "        return json.dumps(self, cls=DefaultJsonEncoder)\n",
        "\n",
        "    @classmethod\n",
        "    def from_json(cls, s):\n",
        "        import json\n",
        "        d = json.loads(s)\n",
        "        return ExplanationBase.from_dict(d)\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(cls, d):\n",
        "        import importlib\n",
        "        module = importlib.import_module(d[\"module\"])\n",
        "        explanation_class = getattr(module, d[\"class\"])\n",
        "        return explanation_class.from_dict(d[\"data\"])"
      ],
      "metadata": {
        "id": "iYheeLoIwQE9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The main function which handles counterfactual explanations for images\n",
        "class CFExplanation(ExplanationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.explanations = []\n",
        "\n",
        "    def __repr__(self):\n",
        "        return repr(self.explanations)\n",
        "\n",
        "    def add(self, image, label, cf, cf_label):\n",
        "        self.explanations.append({\n",
        "            \"image\": image,\n",
        "            \"label\": label,\n",
        "            \"cf\": cf,\n",
        "            \"cf_label\": cf_label\n",
        "        })\n",
        "\n",
        "    def get_explanations(self, index=None):\n",
        "        return self.explanations if index is None else self.explanations[index]\n",
        "\n",
        "    @staticmethod\n",
        "    def _rescale(im):\n",
        "        min_val, max_val = np.min(im), np.max(im)\n",
        "        im = (im - min_val) / (max_val - min_val + 1e-8) * 255\n",
        "        if im.ndim == 2:  # Grayscale to RGB\n",
        "            im = np.tile(im[..., np.newaxis], (1, 1, 3))\n",
        "        return im.astype(np.uint8)\n",
        "\n",
        "    def plot(self, index=None, class_names=None, **kwargs):\n",
        "        import matplotlib.pyplot as plt\n",
        "        import warnings\n",
        "\n",
        "        explanations = self.get_explanations(index)\n",
        "        explanations = (\n",
        "            {index: explanations} if isinstance(explanations, dict) else {i: e for i, e in enumerate(explanations)}\n",
        "        )\n",
        "\n",
        "        indices = sorted(explanations.keys())\n",
        "        if len(indices) > 5:\n",
        "            warnings.warn(f\"Too many instances ({len(indices)} > 5), only showing first 5.\")\n",
        "            indices = indices[:5]\n",
        "        if not indices:\n",
        "            return None\n",
        "\n",
        "        num_rows = len(indices)\n",
        "        fig, axes = plt.subplots(num_rows, 3, figsize=(9, 3 * num_rows))\n",
        "\n",
        "        for i, idx in enumerate(indices):\n",
        "            e = explanations[idx]\n",
        "            titles = [\n",
        "                class_names[e['label']] if class_names else str(e['label']),\n",
        "                f\"CF: {class_names[e['cf_label']]}\" if class_names else f\"CF: {e['cf_label']}\",\n",
        "                \"Difference\"\n",
        "            ]\n",
        "            images = [e[\"image\"], e[\"cf\"], np.abs(e[\"cf\"] - e[\"image\"])]\n",
        "\n",
        "            for j in range(3):\n",
        "                ax = axes[i, j] if num_rows > 1 else axes[j]\n",
        "                ax.imshow(self._rescale(images[j]))\n",
        "                ax.set_title(titles[j])\n",
        "                ax.axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    def _plotly_figure(self, index, class_names=None, **kwargs):\n",
        "        import plotly.express as px\n",
        "        from plotly.subplots import make_subplots\n",
        "\n",
        "        e = self.explanations[index]\n",
        "        labels = [\n",
        "            class_names[e['label']] if class_names else str(e['label']),\n",
        "            f\"CF: {class_names[e['cf_label']]}\" if class_names else f\"CF: {e['cf_label']}\",\n",
        "            \"Difference\"\n",
        "        ]\n",
        "        fig = make_subplots(rows=1, cols=3, subplot_titles=labels)\n",
        "\n",
        "        for i, img in enumerate([e[\"image\"], e[\"cf\"], np.abs(e[\"cf\"] - e[\"image\"])]):\n",
        "            px_fig = px.imshow(self._rescale(img))\n",
        "            fig.add_trace(px_fig.data[0], row=1, col=i + 1)\n",
        "\n",
        "        fig.update_layout(showlegend=False)\n",
        "        fig.update_xaxes(visible=False)\n",
        "        fig.update_yaxes(visible=False)\n",
        "        return fig\n",
        "\n",
        "    def plotly_plot(self, index=0, class_names=None, **kwargs):\n",
        "        assert index is not None, \"`index` must be provided for plotly_plot.\"\n",
        "        return DashFigure(self._plotly_figure(index, class_names=class_names, **kwargs))\n",
        "\n",
        "    def ipython_plot(self, index=0, class_names=None, **kwargs):\n",
        "        import plotly\n",
        "        assert index is not None, \"`index` must be provided for ipython_plot.\"\n",
        "        return plotly.offline.iplot(self._plotly_figure(index, class_names=class_names, **kwargs))\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(cls, d):\n",
        "        explanations = [\n",
        "            {\n",
        "                \"image\": np.array(e[\"image\"]),\n",
        "                \"label\": e[\"label\"],\n",
        "                \"cf\": np.array(e[\"cf\"]),\n",
        "                \"cf_label\": e[\"cf_label\"],\n",
        "            }\n",
        "            for e in d[\"explanations\"]\n",
        "        ]\n",
        "        obj = cls()\n",
        "        obj.explanations = explanations\n",
        "        return obj"
      ],
      "metadata": {
        "id": "o8CaDdXWvzv1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Counterfactual Explainer"
      ],
      "metadata": {
        "id": "FZcfsUCTfC7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable\n",
        "class CounterfactualExplainer(ExplainerBase):\n",
        "    explanation_type = \"local\"\n",
        "    alias = [\"ce\", \"counterfactual\"]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        preprocess_function: Callable,\n",
        "        mode: str = \"classification\",\n",
        "        c=10.0,\n",
        "        kappa=10.0,\n",
        "        binary_search_steps=5,\n",
        "        learning_rate=1e-2,\n",
        "        num_iterations=100,\n",
        "        grad_clip=1e3,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert mode == \"classification\", \"CE supports classification tasks only.\"\n",
        "\n",
        "        model_type = None\n",
        "        if is_tf_available():\n",
        "            if isinstance(model, tf.keras.Model):\n",
        "                model_type = \"tf\"\n",
        "        if model_type is None and is_torch_available():\n",
        "            if isinstance(model, nn.Module):\n",
        "                model_type = \"torch\"\n",
        "        if model_type is None:\n",
        "            raise ValueError(f\"`model` should be a tf.keras.Model \" f\"or a torch.nn.Module instead of {type(model)}\")\n",
        "\n",
        "        self.model = model\n",
        "        self.preprocess_function = preprocess_function\n",
        "        self.create_optimizer = lambda x, y, m: CounterfactualOptimizer(\n",
        "            x,\n",
        "            y,\n",
        "            m,\n",
        "            c=c,\n",
        "            kappa=kappa,\n",
        "            binary_search_steps=binary_search_steps,\n",
        "            learning_rate=learning_rate,\n",
        "            num_iterations=num_iterations,\n",
        "            grad_clip=grad_clip,\n",
        "        )\n",
        "\n",
        "    def _preprocess(self, inputs: Image):\n",
        "        if inputs.values is None:\n",
        "            return None\n",
        "        if self.preprocess_function is not None:\n",
        "            inputs = self.preprocess_function(inputs)\n",
        "            if not isinstance(inputs, np.ndarray):\n",
        "                try:\n",
        "                    inputs = inputs.detach().cpu().numpy()\n",
        "                except AttributeError:\n",
        "                    inputs = inputs.numpy()\n",
        "        else:\n",
        "            inputs = inputs.to_numpy()\n",
        "        return inputs\n",
        "\n",
        "    def _predict(self, inputs):\n",
        "        try:\n",
        "            import torch\n",
        "\n",
        "            self.model.eval()\n",
        "            param = next(self.model.parameters())\n",
        "            x = inputs if isinstance(inputs, torch.Tensor) else torch.tensor(inputs, dtype=torch.get_default_dtype())\n",
        "            scores = self.model(x.to(param.device)).detach().cpu().numpy()\n",
        "        except:\n",
        "            scores = self.model(inputs).numpy()\n",
        "        y = np.argmax(scores, axis=1).astype(int)\n",
        "        return y\n",
        "\n",
        "    def explain(self, X: Image, **kwargs) -> CFExplanation:\n",
        "        assert min(X.shape[1:3]) > 4, f\"The image size ({X.shape[1]}, {X.shape[2]}) is too small.\"\n",
        "        verbose = kwargs.get(\"kwargs\", True)\n",
        "        explanations = CFExplanation()\n",
        "        y = self._predict(self._preprocess(X))\n",
        "\n",
        "        for i in range(len(X)):\n",
        "            x = self._preprocess(X[i])\n",
        "            optimizer = self.create_optimizer(x=x, y=y[i], m=self.model)\n",
        "            # Original image\n",
        "            x = x.squeeze()\n",
        "            if x.ndim == 3 and x.shape[0] == 3:\n",
        "                x = np.transpose(x, (1, 2, 0))\n",
        "\n",
        "            # Get the counterfactual example\n",
        "            cf = optimizer.optimize(verbose=verbose)\n",
        "            if cf is not None:\n",
        "                cf_label = self._predict(cf)[0]\n",
        "                cf = cf.squeeze()\n",
        "                if cf.ndim == 3 and cf.shape[0] == 3:\n",
        "                    cf = np.transpose(cf, (1, 2, 0))\n",
        "            else:\n",
        "                cf_label = None\n",
        "            explanations.add(image=x, label=y[i], cf=cf, cf_label=cf_label)\n",
        "        return explanations"
      ],
      "metadata": {
        "id": "oU86x0deUwP3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "explainer = CounterfactualExplainer(\n",
        "    model=model,\n",
        "    preprocess_function=preprocess\n",
        ")"
      ],
      "metadata": {
        "id": "xkrd15U3wwYu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer Module"
      ],
      "metadata": {
        "id": "28KocECDfG-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The optimizer module - for improving the results\n",
        "class CounterfactualOptimizer:\n",
        "    def __init__(\n",
        "            self,\n",
        "            x0,\n",
        "            target,\n",
        "            model,\n",
        "            c=10.0,\n",
        "            kappa=10.0,\n",
        "            binary_search_steps=5,\n",
        "            learning_rate=1e-2,\n",
        "            num_iterations=1000,\n",
        "            grad_clip=1e3,\n",
        "            gamma=None,\n",
        "            bounds=None,\n",
        "    ):\n",
        "        assert x0.shape[0] == 1\n",
        "        if not isinstance(x0, np.ndarray):\n",
        "            try:\n",
        "                x0 = x0.detach().cpu().numpy()\n",
        "            except AttributeError:\n",
        "                x0 = x0.numpy()\n",
        "\n",
        "        self.x0 = x0\n",
        "        self.target = target\n",
        "        self.model = model\n",
        "        self.c = c\n",
        "        self.kappa = kappa\n",
        "        self.binary_search_steps = binary_search_steps\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.grad_clip = grad_clip\n",
        "        self.gamma = gamma\n",
        "        self.bounds = (np.min(x0), np.max(x0)) if bounds is None else bounds\n",
        "\n",
        "        self.model_type = None\n",
        "        if is_torch_available():\n",
        "            if isinstance(self.model, nn.Module):\n",
        "                self.model_type = \"torch\"\n",
        "        if self.model_type is None and is_tf_available():\n",
        "            if isinstance(self.model, tf.keras.Model):\n",
        "                self.model_type = \"tf\"\n",
        "        if self.model_type is None:\n",
        "            self.model_type = \"other\"\n",
        "        self.num_classes = self._predict(self.x0).shape[1]\n",
        "\n",
        "    def _init_functions(self, c):\n",
        "        if self.model_type == \"torch\":\n",
        "            self.func = _ObjectiveTorch(self.x0, self.target, self.model, c=c, kappa=self.kappa, gamma=self.gamma)\n",
        "        elif self.model_type == \"tf\":\n",
        "            self.func = _ObjectiveTF(self.x0, self.target, self.model, c=c, kappa=self.kappa, gamma=self.gamma)\n",
        "        else:\n",
        "            self.func = self.model\n",
        "\n",
        "    def _predict(self, inputs):\n",
        "        if self.model_type == \"tf\":\n",
        "            inputs = tf.convert_to_tensor(inputs, dtype=tf.keras.backend.floatx())\n",
        "            return self.model(inputs).numpy()\n",
        "        elif self.model_type == \"torch\":\n",
        "            self.model.eval()\n",
        "            param = next(self.model.parameters())\n",
        "            inputs = torch.tensor(inputs, dtype=torch.get_default_dtype()).to(param.device)\n",
        "            return self.model(inputs).detach().cpu().numpy()\n",
        "        else:\n",
        "            return self.model(inputs)\n",
        "\n",
        "    def _compute_gradient(self, model, inputs):\n",
        "        if self.model_type == \"tf\":\n",
        "            inputs = tf.convert_to_tensor(inputs, dtype=tf.keras.backend.floatx())\n",
        "            with tf.GradientTape() as tape:\n",
        "                tape.watch(inputs)\n",
        "                predictions, loss = model(inputs)\n",
        "                gradients = tape.gradient(predictions, inputs).numpy()\n",
        "                loss = loss.numpy()\n",
        "\n",
        "        elif self.model_type == \"torch\":\n",
        "            model.eval()\n",
        "            param = next(model.parameters())\n",
        "            inputs = torch.tensor(inputs, requires_grad=True, dtype=torch.get_default_dtype()).to(param.device)\n",
        "            predictions, loss = model(inputs)\n",
        "            gradients = (\n",
        "                grad(outputs=predictions, inputs=inputs, grad_outputs=torch.ones_like(predictions).to(param.device))[0]\n",
        "                    .detach()\n",
        "                    .cpu()\n",
        "                    .numpy()\n",
        "            )\n",
        "            loss = loss.detach().cpu().numpy()\n",
        "        else:\n",
        "            # Can also apply numerical differentiation to achieve better results\n",
        "            raise NotImplementedError\n",
        "        gradients = np.maximum(np.minimum(gradients, self.grad_clip), -self.grad_clip)\n",
        "        return gradients, loss\n",
        "\n",
        "    def _learning_rate(self, i):\n",
        "        return self.learning_rate * (1 - i / self.num_iterations) ** 0.5\n",
        "\n",
        "    @staticmethod\n",
        "    def _update_const(c, c_lb, c_ub, sol):\n",
        "        if sol is not None:\n",
        "            c_ub = min(c_ub, c)\n",
        "            if c_ub < 1e9:\n",
        "                c = (c_lb + c_ub) * 0.5\n",
        "        else:\n",
        "            c_lb = max(c_lb, c)\n",
        "            if c_ub < 1e9:\n",
        "                c = (c_lb + c_ub) * 0.5\n",
        "            else:\n",
        "                c *= 10\n",
        "        return c, c_lb, c_ub\n",
        "\n",
        "    def optimize(self, verbose=True) -> np.ndarray:\n",
        "        bar = ProgressBar(self.num_iterations) if verbose else None\n",
        "\n",
        "        c_lb, c_ub, c = 0, 1e10, self.c\n",
        "        best_solution, best_loss = None, 1e8\n",
        "        for step in range(self.binary_search_steps):\n",
        "            self._init_functions(c)\n",
        "            x = self.x0.copy()\n",
        "            current_best_sol, current_best_loss = None, 1e8\n",
        "\n",
        "            for iteration in range(self.num_iterations):\n",
        "                # Compute the gradient and loss\n",
        "                gradient, loss = self._compute_gradient(self.func, x)\n",
        "                if loss < 0:\n",
        "                    f = np.sum(np.abs(x - self.x0))\n",
        "                    if f < current_best_loss:\n",
        "                        current_best_loss, current_best_sol = f, x\n",
        "                    if f < best_loss:\n",
        "                        best_loss, best_solution = f, x\n",
        "                # Update x\n",
        "                new_x = x - self._learning_rate(iteration) * gradient\n",
        "                new_x = np.minimum(np.maximum(new_x, self.bounds[0]), self.bounds[1])\n",
        "                if np.sum(np.abs(x - new_x)) < 1e-6:\n",
        "                    break\n",
        "                x = new_x\n",
        "                if verbose:\n",
        "                    bar.print(iteration, prefix=f\"Binary step: {step + 1}\", suffix=\"\")\n",
        "\n",
        "            c, c_lb, c_ub = self._update_const(c, c_lb, c_ub, current_best_sol)\n",
        "        return best_solution"
      ],
      "metadata": {
        "id": "4yQ2XiRGzmaz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import grad\n",
        "class _ObjectiveTorch(nn.Module):\n",
        "        def __init__(self, x0, target, model, c, kappa, gamma=None):\n",
        "            super().__init__()\n",
        "            param = next(model.parameters())\n",
        "            if isinstance(x0, np.ndarray):\n",
        "                self.x0 = torch.tensor(x0, dtype=torch.get_default_dtype()).to(param.device)\n",
        "            else:\n",
        "                self.x0 = x0.to(param.device)\n",
        "            self.num_classes = model(self.x0).shape[1]\n",
        "            self.target = torch.tensor(np.eye(1, self.num_classes, target), dtype=torch.get_default_dtype()).to(\n",
        "                param.device\n",
        "            )\n",
        "            if gamma is None:\n",
        "                self.gamma = 1\n",
        "            else:\n",
        "                self.gamma = torch.tensor(\n",
        "                    np.expand_dims(np.abs(gamma) + 1e-8, axis=0), dtype=torch.get_default_dtype()\n",
        "                ).to(param.device)\n",
        "\n",
        "            self.model = model.eval()\n",
        "            self.c = c\n",
        "            self.kappa = kappa\n",
        "            self.reduce_dims = list(range(1, len(x0.shape)))\n",
        "\n",
        "        def forward(self, x):\n",
        "            # Regularization term\n",
        "            regularization = torch.sum(torch.abs(self.x0 - x) / self.gamma, dim=self.reduce_dims)\n",
        "            # Loss function\n",
        "            prob = self.model(x)\n",
        "            a = torch.sum(prob * self.target, dim=1)\n",
        "            b = torch.max((1 - self.target) * prob - self.target * 10000, dim=1)[0]\n",
        "            loss = nn.functional.relu(a - b + self.kappa)\n",
        "            return torch.mean(self.c * loss + regularization), torch.mean(a - b)"
      ],
      "metadata": {
        "id": "KB82imBz0h-8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Displaying the Results"
      ],
      "metadata": {
        "id": "V61i3kolfL5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explanations = explainer.explain(x_test[0:5])\n",
        "explanations.ipython_plot(index=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "HNXObdpEvCml",
        "outputId": "7f0e04e3-c5fc-4c39-fc5e-bee0843116f2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary step: 5 |███████████████████████████████████████-| 99.0% "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"aa6a3793-8bbd-4fe9-b536-647e050c9ebe\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"aa6a3793-8bbd-4fe9-b536-647e050c9ebe\")) {                    Plotly.newPlot(                        \"aa6a3793-8bbd-4fe9-b536-647e050c9ebe\",                        [{\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: [%{z[0]}, %{z[1]}, %{z[2]}]\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"name\":\"0\",\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABxUlEQVR4Xu2TvariQBiG3yyRGBWEgDYiCqkMplCwsNRCwcJGO+9ACy\\u002fBzkb0FsQuip1YCl5AGtHGQtDKFKkEiegMOYVkOfvhyeKebnefYmDeh\\u002fnmH\\u002fjP30A+nz8ejzQFAFQqlWQySVMAwA8a\\u002fEq1WpUkiaYAgHq9PhgMaArAv6goirVajaYepmlqmhYOh6nwL1oqlYrF4ng8pgIAoCiKpmmhUIgKH3Rdt217v99HIhHqAADr9ZoxFovFqPDBMAzHcQqFAhUAAEVRXNflnL9RtNlsXi6X7XZLhcdwOOScr1arQCBA3VdMp1PGWLvdpgIAkE6nLcu63+\\u002flcpm6r4hGo6fTiTFGhUe\\u002f32eM+ezjxe1LkpRIJAzDoMJDVVUAu92OCh9kWTZNc7PZKIpCHRCPxznnnPNOp0Odh0gDwHGcw+HQaDSWy+VoNPqZZ7NZVVVTqZTrugCe7RtkMpnZbHa9XtknLMs6n8+Px+PZlWWZDvMQaPCJXC73PL4n8\\u002fkcwGQyabVaAETxxS7\\u002fkF6v91ypruvUebw9myAIgiAA8HlSbxd1Xfe3V\\u002fTinfoTDAYB3G43Kr6DZVm2bXe7XSq+w2KxeOPL\\u002f5N8ALCctCde9FLKAAAAAElFTkSuQmCC\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"image\"},{\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: [%{z[0]}, %{z[1]}, %{z[2]}]\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"name\":\"0\",\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAACJklEQVR4Xu3TsUsyYRwH8O9zd9qJhArmEAhCLoGQDv0BIdwfoA0OQWsQCP0HLtGQzY1uBkoOLi5h4OgkpWDT4eIJtRVZz\\u002fPk03Ac+P7w9TV8xz7T8f3e7+G5u+eAXyszDGNjY4Om6zAMIxqN0vRHIpEIgHQ6bds27QAAlmXF43GaAgA0Gng2NzcBWJbl9\\u002fvdRNf1QqEwHA7v7+8zmczh4WG5XP5jZhWapnU6HcdxDMNoNBrX19ehUOjg4ACAz+c7Pj7u9XqBQICOLWdZlpTy\\u002fPwcgK7rW1tb8+3Z2RnnnIT\\u002fsLe39\\u002fz8\\u002fPT0FAwGaQcAaLfbQohYLEaLJW5ubt7f3\\u002ff390mu6zqAcDjMOZdS\\u002fmDRfD7\\u002f+vr6+PhIC4AxBuDy8lIIcXd35\\u002fP56B1\\u002fU6vVhBAnJye0AAAkEonJZPL5+el+tJWEQqHRaPT19UULAABj7OLignO+8DlcC86paZrb29vVapUWAACl1M7ODmNsMBjQbolAINDtdh8eHtyfiojFYkopKeXp6SntPAYNgOl0att2LpdrtVpXV1dKKcbYbDZLpVLJZDKRSEgp3YROLre7u1uv19\\u002fe3oQQUkohBOd8PB47jsM555wLIUzTpGMeRoM56XQ6mUy610qp29tbAJVK5ejoSNM098D+H6VSyd17KpWinWfBO12Oefr9Pu08P15UeWgxZ8E5Xc40TaXUx8cHLdbhOM7Ly0uxWKTFOprNZjabpemvOd8C1dyLo\\u002fsULAAAAABJRU5ErkJggg==\",\"xaxis\":\"x2\",\"yaxis\":\"y2\",\"type\":\"image\"},{\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: [%{z[0]}, %{z[1]}, %{z[2]}]\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"name\":\"0\",\"source\":\"data:image\\u002fpng;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAA10lEQVR4Xu2SUQqDMBBEZ+Ou+ieCIF7FM3gQz+c9PIQnsR8LIU2NTQzSFvq+luzMMCYCf6Jh5rqu\\u002fdMcRKTve\\u002f80ia7rABhj\\u002fEUEQU\\u002fTNDoQkQ7MPM\\u002fzvu\\u002fbto3jWFWVXSVARGoTkXVdl2Vp23aaJgBlWQIwxiTnuoaiKIZhcJbAsyCKt7epAvs1WTAzACISER18xQkhtVswpDlGDa83kBzkETJf6YiIOro91xxwnvt6LQm4ufqfX+xocf0aZ7Ouh4bILXvILX1vaZr19CHcF\\u002ft6fqfpZ3gAaMkPdbRlIyYAAAAASUVORK5CYII=\",\"xaxis\":\"x3\",\"yaxis\":\"y3\",\"type\":\"image\"}],                        {\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"4\",\"x\":0.14444444444444446,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"CF: 9\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Difference\",\"x\":0.8555555555555556,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"showlegend\":false,\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.2888888888888889],\"visible\":false},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"visible\":false},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.35555555555555557,0.6444444444444445],\"visible\":false},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"visible\":false},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.7111111111111111,1.0],\"visible\":false},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"visible\":false}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('aa6a3793-8bbd-4fe9-b536-647e050c9ebe');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}